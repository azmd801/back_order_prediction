{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOlubuLusT6N8gghbpHNeBL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/azmd801/back_order_prediction/blob/main/notebook/Data_transformation_%26_Model_Selection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Approcah for data transformation"
      ],
      "metadata": {
        "id": "gcyP4TOolYt7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are lot of options availble for preprocessing data all these options are hyperparameters and can be cross validated to find the best preprocessing pipelin\n",
        "\n",
        "### Fixed steps which will done initially before any data transformation\n",
        "* dropping unncessary features  `'sku'`\n",
        "\n",
        "### Diffrent pre-processing optiona availbale\n",
        "\n",
        "1. use all the data as it is without any modification\n",
        "2. Use winsorization to handle outlier\n",
        "3. removing extreme sparse feature  `'in_transit_qty'`, `'local_bo_qty'`, `'pieces_past_due'`\n",
        "4. Removing extreme imbalance features `'potential_issue'`, `'oe_constraint'`, and `'rev_stop`\n",
        "5. Removing extreme sparse features\n",
        "\n",
        "### Options for Handling categorical feature\n",
        "1. Use one hot encode by removing first dummy variable\n",
        "2.Keeping all the variabbles\n",
        "\n",
        "### Options for imputation\n",
        "\n",
        " * `lead_time` has 100894 missing records (6%) which is large so these records cant be dropped\n",
        " * For rest of the features there is only one missing records so these will be dropped\n",
        " * For handiling the missing value of lead_time knn_imputer and median imputaion will be used\n",
        " * add_indicator will be explored\n",
        "\n",
        "### Refrences\n",
        "\n",
        " * https://chinmaydalvi.medium.com/backorder-prediction-using-machine-learning-cbe2a7d2cfa4\n"
      ],
      "metadata": {
        "id": "u82caR-iagM7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing required libraries"
      ],
      "metadata": {
        "id": "lZAEXyA0va3-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from typing import List\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from imblearn.pipeline import Pipeline as Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import FunctionTransformer, OneHotEncoder, StandardScaler,LabelEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.impute import KNNImputer\n",
        "from scipy.stats.mstats import winsorize\n",
        "from sklearn.preprocessing import PowerTransformer\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# intalling required libraries\n",
        "!pip install --quiet  unrar\n",
        "!pip install --quiet  patool\n",
        "import os\n",
        "import patoolib\n",
        "\n",
        "!pip install --quiet optuna\n",
        "import optuna\n",
        "\n",
        "optuna.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "rpq1B819aetL",
        "outputId": "d2e585e6-beeb-4684-97b2-0ca437385f95"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.5/77.5 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m390.6/390.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'3.2.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Custom functions"
      ],
      "metadata": {
        "id": "5WrCbTEdvqoY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Some functions for creating feature transformation pipeline\n",
        "\n",
        "## function to drop columns\n",
        "\n",
        "def drop_col(df: pd.DataFrame, columns: List[str], drop: bool =True) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Drop columns from a DataFrame.\n",
        "\n",
        "    Parameters:\n",
        "    - df: Input DataFrame.\n",
        "    - columns: List of column names to drop.\n",
        "\n",
        "    Returns:\n",
        "    - DataFrame: DataFrame with the specified columns dropped.\n",
        "    \"\"\"\n",
        "    # if 'sku' in df.columns:\n",
        "    #   df.drop('sku',inplace=True,axis=1)\n",
        "\n",
        "    if not drop:\n",
        "      return df.drop('sku',axis=1)\n",
        "\n",
        "    return df.drop('sku',axis=1).drop(columns, axis=1)\n",
        "\n",
        "from sklearn.base import TransformerMixin\n",
        "\n",
        "## custom class with fit and tranform to perform winsorization\n",
        "\n",
        "class Winsorizer(TransformerMixin):\n",
        "    def __init__(self, change=True):\n",
        "        \"\"\"\n",
        "        Initialize the Winsorizer transformer.\n",
        "\n",
        "        Parameters:\n",
        "        - lower_quantile (float): Lower quantile for winsorization (default: 0.05).\n",
        "        - upper_quantile (float): Upper quantile for winsorization (default: 0.95).\n",
        "        \"\"\"\n",
        "        self.change = change\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        \"\"\"\n",
        "        Fit the Winsorizer transformer.\n",
        "\n",
        "        Parameters:\n",
        "        - X (array-like): Input data.\n",
        "        - y: Ignored.\n",
        "\n",
        "        Returns:\n",
        "        - self: Returns the instance of the transformer.\n",
        "        \"\"\"\n",
        "        # Calculate the percentiles\n",
        "        p0 = np.nanpercentile(X, 0)\n",
        "        p100 = np.nanpercentile(X, 100)\n",
        "\n",
        "        # Calculate the lower and upper IQR\n",
        "        Q1 = np.nanpercentile(X, 25)\n",
        "        Q3 = np.nanpercentile(X, 75)\n",
        "        IQR = Q3 - Q1\n",
        "\n",
        "        # Calculate the lower and upper bounds\n",
        "        self.lower_bound = max(Q1 - (1.5 * IQR),p0)\n",
        "        self.upper_bound = min(Q3 + (1.5 * IQR),p100)\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        \"\"\"\n",
        "        Transform the input data using winsorization.\n",
        "\n",
        "        Parameters:\n",
        "        - X (array-like): Input data to be transformed.\n",
        "\n",
        "        Returns:\n",
        "        - X_transformed (array-like): Transformed data after winsorization.\n",
        "        \"\"\"\n",
        "\n",
        "        if not self.change:\n",
        "          return X\n",
        "\n",
        "        X_clipped = np.clip(X, self.lower_bound, self.upper_bound)\n",
        "        return X_clipped\n",
        "\n",
        "    def get_feature_names_out(self, input_features):\n",
        "        \"\"\"\n",
        "        Get the feature names after transformation.\n",
        "\n",
        "        Parameters:\n",
        "        - input_features (array-like): Input feature names.\n",
        "\n",
        "        Returns:\n",
        "        - output_features (array-like): Transformed feature names.\n",
        "        \"\"\"\n",
        "        return input_features"
      ],
      "metadata": {
        "id": "g7WvlkkMt6n8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-rKcwLRO3PBy"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Ingestion"
      ],
      "metadata": {
        "id": "2Qanj-wuZAYP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "Ji7vGgK7WtlH",
        "outputId": "37e75ae1-9452-46d6-d4f8-388a748a7ae2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-07-26 09:47:08--  https://github.com/rodrigosantis1/backorder_prediction/raw/master/dataset.rar\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/rodrigosantis1/backorder_prediction/master/dataset.rar [following]\n",
            "--2023-07-26 09:47:08--  https://raw.githubusercontent.com/rodrigosantis1/backorder_prediction/master/dataset.rar\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 24741696 (24M) [application/octet-stream]\n",
            "Saving to: ‘dataset/dataset.rar’\n",
            "\n",
            "dataset/dataset.rar 100%[===================>]  23.59M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2023-07-26 09:47:09 (163 MB/s) - ‘dataset/dataset.rar’ saved [24741696/24741696]\n",
            "\n",
            "patool: Extracting dataset/dataset.rar ...\n",
            "patool: running /usr/bin/unrar x -- /content/dataset/dataset.rar\n",
            "patool:     with cwd='dataset'\n",
            "patool: ... dataset/dataset.rar extracted to `dataset'.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'dataset'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "\n",
        "# Create a directory to store the dataset\n",
        "if not os.path.exists(\"dataset\"):\n",
        "    os.makedirs(\"dataset\")\n",
        "\n",
        "# Download the RAR file from GitHub\n",
        "!wget -O dataset/dataset.rar https://github.com/rodrigosantis1/backorder_prediction/raw/master/dataset.rar\n",
        "\n",
        "# Extract the RAR file\n",
        "patoolib.extract_archive(\"dataset/dataset.rar\", outdir=\"dataset\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reading th data\n",
        "raw_data = pd.read_csv(r\"/content/dataset/Kaggle_Training_Dataset_v2.csv\")\n",
        "raw_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_JU4LKkpFSX",
        "outputId": "9143c27a-f3a8-4246-a559-cb319c064a91"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1687861, 23)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "2efQtjdnZZkO",
        "outputId": "b7eb9481-6b45-4472-8823-55b742f6aa87"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    sku  national_inv  lead_time  in_transit_qty  \\\n",
              "0               1026827           0.0        NaN             0.0   \n",
              "1               1043384           2.0        9.0             0.0   \n",
              "2               1043696           2.0        NaN             0.0   \n",
              "3               1043852           7.0        8.0             0.0   \n",
              "4               1044048           8.0        NaN             0.0   \n",
              "...                 ...           ...        ...             ...   \n",
              "1687856         1373987          -1.0        NaN             0.0   \n",
              "1687857         1524346          -1.0        9.0             0.0   \n",
              "1687858         1439563          62.0        9.0            16.0   \n",
              "1687859         1502009          19.0        4.0             0.0   \n",
              "1687860  (1687860 rows)           NaN        NaN             NaN   \n",
              "\n",
              "         forecast_3_month  forecast_6_month  forecast_9_month  sales_1_month  \\\n",
              "0                     0.0               0.0               0.0            0.0   \n",
              "1                     0.0               0.0               0.0            0.0   \n",
              "2                     0.0               0.0               0.0            0.0   \n",
              "3                     0.0               0.0               0.0            0.0   \n",
              "4                     0.0               0.0               0.0            0.0   \n",
              "...                   ...               ...               ...            ...   \n",
              "1687856               5.0               7.0               9.0            1.0   \n",
              "1687857               7.0               9.0              11.0            0.0   \n",
              "1687858              39.0              87.0             126.0           35.0   \n",
              "1687859               0.0               0.0               0.0            2.0   \n",
              "1687860               NaN               NaN               NaN            NaN   \n",
              "\n",
              "         sales_3_month  sales_6_month  ...  pieces_past_due  perf_6_month_avg  \\\n",
              "0                  0.0            0.0  ...              0.0            -99.00   \n",
              "1                  0.0            0.0  ...              0.0              0.99   \n",
              "2                  0.0            0.0  ...              0.0            -99.00   \n",
              "3                  0.0            0.0  ...              0.0              0.10   \n",
              "4                  0.0            0.0  ...              0.0            -99.00   \n",
              "...                ...            ...  ...              ...               ...   \n",
              "1687856            3.0            3.0  ...              0.0            -99.00   \n",
              "1687857            8.0           11.0  ...              0.0              0.86   \n",
              "1687858           63.0          153.0  ...              0.0              0.86   \n",
              "1687859            7.0           12.0  ...              0.0              0.73   \n",
              "1687860            NaN            NaN  ...              NaN               NaN   \n",
              "\n",
              "        perf_12_month_avg  local_bo_qty  deck_risk  oe_constraint  ppap_risk  \\\n",
              "0                  -99.00           0.0         No             No         No   \n",
              "1                    0.99           0.0         No             No         No   \n",
              "2                  -99.00           0.0        Yes             No         No   \n",
              "3                    0.13           0.0         No             No         No   \n",
              "4                  -99.00           0.0        Yes             No         No   \n",
              "...                   ...           ...        ...            ...        ...   \n",
              "1687856            -99.00           1.0         No             No         No   \n",
              "1687857              0.84           1.0        Yes             No         No   \n",
              "1687858              0.84           6.0         No             No         No   \n",
              "1687859              0.78           1.0         No             No         No   \n",
              "1687860               NaN           NaN        NaN            NaN        NaN   \n",
              "\n",
              "        stop_auto_buy rev_stop went_on_backorder  \n",
              "0                 Yes       No                No  \n",
              "1                 Yes       No                No  \n",
              "2                 Yes       No                No  \n",
              "3                 Yes       No                No  \n",
              "4                 Yes       No                No  \n",
              "...               ...      ...               ...  \n",
              "1687856           Yes       No                No  \n",
              "1687857            No       No               Yes  \n",
              "1687858           Yes       No                No  \n",
              "1687859           Yes       No                No  \n",
              "1687860           NaN      NaN               NaN  \n",
              "\n",
              "[1687861 rows x 23 columns]"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-1d7dc5ca-df77-4ff3-bff6-b83d552d8185\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sku</th>\n",
              "      <th>national_inv</th>\n",
              "      <th>lead_time</th>\n",
              "      <th>in_transit_qty</th>\n",
              "      <th>forecast_3_month</th>\n",
              "      <th>forecast_6_month</th>\n",
              "      <th>forecast_9_month</th>\n",
              "      <th>sales_1_month</th>\n",
              "      <th>sales_3_month</th>\n",
              "      <th>sales_6_month</th>\n",
              "      <th>...</th>\n",
              "      <th>pieces_past_due</th>\n",
              "      <th>perf_6_month_avg</th>\n",
              "      <th>perf_12_month_avg</th>\n",
              "      <th>local_bo_qty</th>\n",
              "      <th>deck_risk</th>\n",
              "      <th>oe_constraint</th>\n",
              "      <th>ppap_risk</th>\n",
              "      <th>stop_auto_buy</th>\n",
              "      <th>rev_stop</th>\n",
              "      <th>went_on_backorder</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1026827</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-99.00</td>\n",
              "      <td>-99.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1043384</td>\n",
              "      <td>2.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.99</td>\n",
              "      <td>0.99</td>\n",
              "      <td>0.0</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1043696</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-99.00</td>\n",
              "      <td>-99.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1043852</td>\n",
              "      <td>7.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.0</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1044048</td>\n",
              "      <td>8.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-99.00</td>\n",
              "      <td>-99.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1687856</th>\n",
              "      <td>1373987</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-99.00</td>\n",
              "      <td>-99.00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1687857</th>\n",
              "      <td>1524346</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.86</td>\n",
              "      <td>0.84</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1687858</th>\n",
              "      <td>1439563</td>\n",
              "      <td>62.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>126.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>63.0</td>\n",
              "      <td>153.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.86</td>\n",
              "      <td>0.84</td>\n",
              "      <td>6.0</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1687859</th>\n",
              "      <td>1502009</td>\n",
              "      <td>19.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.73</td>\n",
              "      <td>0.78</td>\n",
              "      <td>1.0</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1687860</th>\n",
              "      <td>(1687860 rows)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1687861 rows × 23 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1d7dc5ca-df77-4ff3-bff6-b83d552d8185')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-4ae71815-2252-463d-a87a-85ef31f09b59\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4ae71815-2252-463d-a87a-85ef31f09b59')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-4ae71815-2252-463d-a87a-85ef31f09b59 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1d7dc5ca-df77-4ff3-bff6-b83d552d8185 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1d7dc5ca-df77-4ff3-bff6-b83d552d8185');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data cleaning"
      ],
      "metadata": {
        "id": "BTKRddsdAkr4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dropping the na record for all the features except for feature 'lead_time'\n",
        "\n",
        "print(f\"Shape of data before dropping na {raw_data.shape}\\n\")\n",
        "raw_data.dropna(subset=raw_data.columns.drop('lead_time'),inplace=True)\n",
        "print(f\"Shape of data after dropping na {raw_data.shape}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_zy3AIJxY-8",
        "outputId": "a01d87bc-d830-45c5-ae30-329b40f2918b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of data before dropping na (1687861, 23)\n",
            "\n",
            "Shape of data after dropping na (1687860, 23)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Expermentin with different ML training pipeline using optuna   "
      ],
      "metadata": {
        "id": "HY5O4EyvAttu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing required Variables for optimizing the objective function"
      ],
      "metadata": {
        "id": "g727vQzMp1pz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw_data.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFalZNzmu_sD",
        "outputId": "5f715a4a-4a52-4ce6-c010-f9695cce4651"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sku                   object\n",
              "national_inv         float64\n",
              "lead_time            float64\n",
              "in_transit_qty       float64\n",
              "forecast_3_month     float64\n",
              "forecast_6_month     float64\n",
              "forecast_9_month     float64\n",
              "sales_1_month        float64\n",
              "sales_3_month        float64\n",
              "sales_6_month        float64\n",
              "sales_9_month        float64\n",
              "min_bank             float64\n",
              "potential_issue       object\n",
              "pieces_past_due      float64\n",
              "perf_6_month_avg     float64\n",
              "perf_12_month_avg    float64\n",
              "local_bo_qty         float64\n",
              "deck_risk             object\n",
              "oe_constraint         object\n",
              "ppap_risk             object\n",
              "stop_auto_buy         object\n",
              "rev_stop              object\n",
              "went_on_backorder     object\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Take 10000 random samples from the dataset while stratifying based on a specific column (e.g., 'label')\n",
        "sample_size = 100000\n",
        "samples = raw_data.sample(n=sample_size, replace=False)\n",
        "samples.head()\n",
        "\n",
        "# spliting X_train and y_train\n",
        "y_train = LabelEncoder().fit_transform(samples['went_on_backorder'])\n",
        "X_train = samples.drop('went_on_backorder',axis=1)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)"
      ],
      "metadata": {
        "id": "FtO8gr1EfMaz",
        "outputId": "e479b03a-88d3-4c67-9754-666f8504d801",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100000, 22)\n",
            "(100000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # spliting X_train and y_train\n",
        "# y_train = LabelEncoder().fit_transform(raw_data['went_on_backorder'])\n",
        "# X_train = raw_data.drop('went_on_backorder',axis=1)\n",
        "\n",
        "# print(X_train.shape)\n",
        "# print(y_train.shape)"
      ],
      "metadata": {
        "id": "sTP5cmhm33XE"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "id": "dee0co8ZpyXE",
        "outputId": "1f328f43-8d8b-4bf6-85c7-8264b40eabb2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# segregating numeric and categorical fetaure\n",
        "numeric_cols = X_train.columns[X_train.dtypes != 'object']\n",
        "print(f'Numeric columns: {numeric_cols}\\n')\n",
        "\n",
        "cat_cols = X_train.columns[X_train.dtypes == 'object'].drop('sku')\n",
        "print(f'Categorical columns: {cat_cols}\\n')\n",
        "\n",
        "print(f'Target columns : went_on_backorder')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMRkDXFylhJ4",
        "outputId": "e03f6ae0-c86b-4b9b-b5ae-bab06a87e23e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Numeric columns: Index(['national_inv', 'lead_time', 'in_transit_qty', 'forecast_3_month',\n",
            "       'forecast_6_month', 'forecast_9_month', 'sales_1_month',\n",
            "       'sales_3_month', 'sales_6_month', 'sales_9_month', 'min_bank',\n",
            "       'pieces_past_due', 'perf_6_month_avg', 'perf_12_month_avg',\n",
            "       'local_bo_qty'],\n",
            "      dtype='object')\n",
            "\n",
            "Categorical columns: Index(['potential_issue', 'deck_risk', 'oe_constraint', 'ppap_risk',\n",
            "       'stop_auto_buy', 'rev_stop'],\n",
            "      dtype='object')\n",
            "\n",
            "Target columns : went_on_backorder\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "useless_cols = ['in_transit_qty', 'local_bo_qty', 'pieces_past_due','potential_issue', 'oe_constraint','rev_stop']"
      ],
      "metadata": {
        "id": "HnWztJGb85Mb"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the proportion of zeros in each column\n",
        "zero_proportion = (X_train == 0).sum() / len(X_train)\n",
        "\n",
        "# Filter features with more than 30 percent zeros\n",
        "threshold = 0.3\n",
        "filtered_data = X_train.drop(columns=zero_proportion[zero_proportion < threshold].index)\n",
        "\n",
        "# Get the feature names of the remaining columns\n",
        "sparse_cols = filtered_data.columns.tolist()\n",
        "\n",
        "sparse_cols"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFCDVenW9E4D",
        "outputId": "1c61895c-030c-49ad-df0e-806e0b01a697"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['in_transit_qty',\n",
              " 'forecast_3_month',\n",
              " 'forecast_6_month',\n",
              " 'forecast_9_month',\n",
              " 'sales_1_month',\n",
              " 'sales_3_month',\n",
              " 'sales_6_month',\n",
              " 'sales_9_month',\n",
              " 'min_bank',\n",
              " 'pieces_past_due',\n",
              " 'local_bo_qty']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MLPipeline:\n",
        "    def __init__(self, imputer_type, drop_and_winsorize, classifier, columns_to_drop,\n",
        "                 add_indicator=False, keep_first=False):\n",
        "\n",
        "        self.imputer_type = imputer_type\n",
        "        self.drop_and_winsorize = drop_and_winsorize\n",
        "        self.classifier = classifier\n",
        "        self.columns_to_drop = columns_to_drop\n",
        "        self.useless_cols = useless_cols\n",
        "        self.sparse_cols = sparse_cols\n",
        "        self.numeric_cols = numeric_cols\n",
        "        self.cat_cols = cat_cols\n",
        "        self.add_indicator = add_indicator\n",
        "        self.keep_first = keep_first\n",
        "\n",
        "        if self.drop_and_winsorize:\n",
        "            self.drop_cols = self.useless_cols if self.columns_to_drop == 'useless' else self.sparse_cols\n",
        "        else:\n",
        "            self.drop_cols = []\n",
        "\n",
        "        self.num_cols_used = [col for col in self.numeric_cols if col not in self.drop_cols]\n",
        "        self.cat_cols_used = [col for col in self.cat_cols if col not in self.drop_cols]\n",
        "\n",
        "    def _create_classifier(self):\n",
        "        if self.classifier == 'RandomForest':\n",
        "            clf = RandomForestClassifier()\n",
        "\n",
        "        elif self.classifier == 'SVC':\n",
        "            clf = SVC()\n",
        "\n",
        "        elif self.classifier == 'LogisticRegression':\n",
        "            clf = LogisticRegression(solver='liblinear')\n",
        "\n",
        "        elif self.classifier == 'XGBoost':\n",
        "            clf = XGBClassifier()\n",
        "\n",
        "        else:\n",
        "            raise ValueError(f\"Invalid classifier: {self.classifier}\")\n",
        "\n",
        "        return clf\n",
        "\n",
        "    def _drop_col(self, X):\n",
        "        if not self.drop_and_winsorize:\n",
        "          # Always drop 'sku' column and additional columns specified in drop_cols\n",
        "            X.drop('sku',axis=1)\n",
        "\n",
        "        columns_to_drop = ['sku'] + self.drop_cols\n",
        "        return X.drop(columns_to_drop, axis=1)\n",
        "\n",
        "    def create_pipeline(self):\n",
        "        # Conditional creation of imputer based on 'imputer_type'\n",
        "        if self.imputer_type == 'knn':\n",
        "            imp = KNNImputer(weights='distance', add_indicator=self.add_indicator)\n",
        "        else:\n",
        "            imp = SimpleImputer(strategy='median', add_indicator=self.add_indicator)\n",
        "\n",
        "        # Conditional initialization of cat_encoder based on 'keep_first'\n",
        "        cat_encoder = OneHotEncoder(drop='first') if self.keep_first else OneHotEncoder()\n",
        "\n",
        "        # Constructing the numerical pipeline\n",
        "        num_pipeline = Pipeline([\n",
        "            ('scaler', StandardScaler()),\n",
        "            ('imputer', imp),\n",
        "            ('outlier_clipping', Winsorizer(change=self.drop_and_winsorize)),\n",
        "        ])\n",
        "\n",
        "        # Constructing the categorical pipeline\n",
        "        cat_pipeline = Pipeline([\n",
        "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "            ('onehotencoder', cat_encoder),\n",
        "        ])\n",
        "\n",
        "        # Constructing the training pipeline\n",
        "        clf = self._create_classifier()\n",
        "        training_pipeline = Pipeline([\n",
        "            ('Drop_Columns', FunctionTransformer(self._drop_col)),\n",
        "            ('Balancing', RandomOverSampler()),\n",
        "            ('Feature_transform', ColumnTransformer([\n",
        "                ('num_pipeline', num_pipeline, self.num_cols_used),\n",
        "                ('cat_pipeline', cat_pipeline, self.cat_cols_used),\n",
        "            ])),\n",
        "            ('Model training', clf)\n",
        "        ])\n",
        "\n",
        "        return training_pipeline"
      ],
      "metadata": {
        "id": "s8ycsqRKPGhW"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into train and validation sets (80% train, 20% validation)\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.4, random_state=42)\n",
        "print(\"Shape of X_train:\", X_train.shape)\n",
        "print(\"Shape of y_train:\", y_train.shape)\n",
        "print(\"Shape of X_val:\", X_val.shape)\n",
        "print(\"Shape of y_val:\", y_val.shape)"
      ],
      "metadata": {
        "id": "j01ypXCTixdP",
        "outputId": "5635fa4c-b973-40d0-d7b8-6119cbf296a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X_train: (60000, 22)\n",
            "Shape of y_train: (60000,)\n",
            "Shape of X_val: (40000, 22)\n",
            "Shape of y_val: (40000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimizing objective fucntion to get best ML pipeline"
      ],
      "metadata": {
        "id": "sX5dnFPyqmQ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import balanced_accuracy_score"
      ],
      "metadata": {
        "id": "dIntdpEM1nVv"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining Objective function which will be optimized\n",
        "\n",
        "def objective(trial):\n",
        "\n",
        "    # Sampling the classifiers\n",
        "    classifier = trial.suggest_categorical('classifier', ['RandomForest', 'SVC', 'LogisticRegression', 'XGBoost'])\n",
        "\n",
        "    # experimenting with dropping unnecessary columns and outlier handling\n",
        "    drop_and_winsorize = trial.suggest_int('drop_and_winsorize',0,1)\n",
        "\n",
        "    # experimenting with columns to drop\n",
        "    columns_to_drop = trial.suggest_categorical('columns_to_drop', ['useless', 'sparse'])\n",
        "\n",
        "    # experimenting with imputers\n",
        "    add_indicator = trial.suggest_int('add_indicator',0,1)\n",
        "    imputer = trial.suggest_categorical('imputer',['simple','knn'])\n",
        "\n",
        "    # experimenting with one hot encoding\n",
        "    keep_first = trial.suggest_int('keep_first',0,1)\n",
        "\n",
        "    pipeline_params = {\n",
        "    'imputer_type': imputer,\n",
        "    'drop_and_winsorize': drop_and_winsorize,\n",
        "    'classifier': classifier,\n",
        "    'columns_to_drop': columns_to_drop,\n",
        "    'add_indicator': add_indicator,\n",
        "    'keep_first': keep_first\n",
        "    }\n",
        "    pipeline = MLPipeline(**pipeline_params)\n",
        "\n",
        "   # constructing training pipeline\n",
        "    training_pipeline = pipeline.create_pipeline()\n",
        "\n",
        "    training_pipeline.fit(X_train,y_train)\n",
        "\n",
        "    scores = balanced_accuracy_score(y_val, training_pipeline.predict(X_val))\n",
        "    # scorer = make_scorer(balanced_accuracy_score)\n",
        "\n",
        "    # scores = cross_val_score(training_pipeline, X_train, y_train, n_jobs=-1, cv=5, scoring=scorer)\n",
        "    # report_cross_validation_scores(trial, scores)\n",
        "\n",
        "    # Returning the cross-validated mean score\n",
        "    return scores.mean()\n"
      ],
      "metadata": {
        "id": "4kx0gLGuf_BA"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "study = optuna.create_study(direction=\"maximize\")\n",
        "# terminator = TerminatorCallback()\n",
        "study.optimize(objective, n_trials=100, n_jobs=-1, )#, #callbacks=[terminator])\n",
        "trial = study.best_trial\n",
        "\n",
        "print('f1_score: {}'.format(trial.value))\n",
        "print(\"Best hyperparameters: {}\".format(trial.params))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OpLhPFxghwvo",
        "outputId": "c79b3d16-fd13-490a-a581-7492d64e173e"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-07-26 10:55:00,571] A new study created in memory with name: no-name-354ea06c-7bde-4ff0-a76c-dc7ee9ee6ad4\n",
            "[I 2023-07-26 10:58:19,605] Trial 0 finished with value: 0.6517108737164384 and parameters: {'classifier': 'XGBoost', 'drop_and_winsorize': 1, 'columns_to_drop': 'sparse', 'add_indicator': 0, 'imputer': 'knn', 'keep_first': 1}. Best is trial 0 with value: 0.6517108737164384.\n",
            "[I 2023-07-26 10:59:37,068] Trial 1 finished with value: 0.5313483998358641 and parameters: {'classifier': 'RandomForest', 'drop_and_winsorize': 0, 'columns_to_drop': 'sparse', 'add_indicator': 0, 'imputer': 'knn', 'keep_first': 1}. Best is trial 0 with value: 0.6517108737164384.\n",
            "[I 2023-07-26 10:59:40,396] Trial 3 finished with value: 0.7867594198675127 and parameters: {'classifier': 'LogisticRegression', 'drop_and_winsorize': 1, 'columns_to_drop': 'useless', 'add_indicator': 0, 'imputer': 'simple', 'keep_first': 1}. Best is trial 3 with value: 0.7867594198675127.\n",
            "[I 2023-07-26 11:00:24,939] Trial 4 finished with value: 0.6672253036388811 and parameters: {'classifier': 'XGBoost', 'drop_and_winsorize': 0, 'columns_to_drop': 'sparse', 'add_indicator': 0, 'imputer': 'simple', 'keep_first': 0}. Best is trial 3 with value: 0.7867594198675127.\n",
            "[I 2023-07-26 11:04:26,557] Trial 5 finished with value: 0.6299727797282901 and parameters: {'classifier': 'XGBoost', 'drop_and_winsorize': 1, 'columns_to_drop': 'useless', 'add_indicator': 0, 'imputer': 'knn', 'keep_first': 0}. Best is trial 3 with value: 0.7867594198675127.\n",
            "[I 2023-07-26 11:04:50,062] Trial 6 finished with value: 0.6446709943398834 and parameters: {'classifier': 'XGBoost', 'drop_and_winsorize': 1, 'columns_to_drop': 'sparse', 'add_indicator': 1, 'imputer': 'simple', 'keep_first': 1}. Best is trial 3 with value: 0.7867594198675127.\n",
            "[I 2023-07-26 11:05:04,819] Trial 7 finished with value: 0.6771042587832874 and parameters: {'classifier': 'LogisticRegression', 'drop_and_winsorize': 0, 'columns_to_drop': 'sparse', 'add_indicator': 1, 'imputer': 'simple', 'keep_first': 0}. Best is trial 3 with value: 0.7867594198675127.\n",
            "[I 2023-07-26 12:11:00,250] Trial 5 finished with value: 0.6583903219827443 and parameters: {'classifier': 'SVC', 'drop_and_winsorize': 0, 'columns_to_drop': 'sparse', 'add_indicator': 1, 'imputer': 'knn', 'keep_first': 0}. Best is trial 4 with value: 0.7009333846619019.\n",
            "[I 2023-07-26 12:11:32,901] Trial 8 finished with value: 0.6670779884712044 and parameters: {'classifier': 'SVC', 'drop_and_winsorize': 0, 'columns_to_drop': 'useless', 'add_indicator': 0, 'imputer': 'simple', 'keep_first': 0}. Best is trial 3 with value: 0.7867594198675127.\n",
            "[I 2023-07-26 12:12:49,399] Trial 2 finished with value: 0.665430826332738 and parameters: {'classifier': 'SVC', 'drop_and_winsorize': 0, 'columns_to_drop': 'sparse', 'add_indicator': 1, 'imputer': 'simple', 'keep_first': 0}. Best is trial 3 with value: 0.7867594198675127.\n",
            "[I 2023-07-26 12:14:24,836] Trial 9 finished with value: 0.5275485613290006 and parameters: {'classifier': 'RandomForest', 'drop_and_winsorize': 0, 'columns_to_drop': 'useless', 'add_indicator': 0, 'imputer': 'knn', 'keep_first': 1}. Best is trial 3 with value: 0.7867594198675127.\n",
            "[I 2023-07-26 12:14:28,664] Trial 11 finished with value: 0.7905147959783139 and parameters: {'classifier': 'LogisticRegression', 'drop_and_winsorize': 1, 'columns_to_drop': 'useless', 'add_indicator': 1, 'imputer': 'simple', 'keep_first': 1}. Best is trial 11 with value: 0.7905147959783139.\n",
            "[I 2023-07-26 12:14:30,948] Trial 12 finished with value: 0.8021456409531167 and parameters: {'classifier': 'LogisticRegression', 'drop_and_winsorize': 1, 'columns_to_drop': 'useless', 'add_indicator': 1, 'imputer': 'simple', 'keep_first': 1}. Best is trial 12 with value: 0.8021456409531167.\n",
            "[I 2023-07-26 12:14:33,151] Trial 13 finished with value: 0.802258939709348 and parameters: {'classifier': 'LogisticRegression', 'drop_and_winsorize': 1, 'columns_to_drop': 'useless', 'add_indicator': 1, 'imputer': 'simple', 'keep_first': 1}. Best is trial 13 with value: 0.802258939709348.\n",
            "[I 2023-07-26 12:14:35,202] Trial 14 finished with value: 0.7836995499119859 and parameters: {'classifier': 'LogisticRegression', 'drop_and_winsorize': 1, 'columns_to_drop': 'useless', 'add_indicator': 1, 'imputer': 'simple', 'keep_first': 1}. Best is trial 13 with value: 0.802258939709348.\n",
            "[I 2023-07-26 12:14:37,322] Trial 15 finished with value: 0.8009516738395761 and parameters: {'classifier': 'LogisticRegression', 'drop_and_winsorize': 1, 'columns_to_drop': 'useless', 'add_indicator': 1, 'imputer': 'simple', 'keep_first': 1}. Best is trial 13 with value: 0.802258939709348.\n",
            "[I 2023-07-26 12:14:40,048] Trial 16 finished with value: 0.7938594752580159 and parameters: {'classifier': 'LogisticRegression', 'drop_and_winsorize': 1, 'columns_to_drop': 'useless', 'add_indicator': 1, 'imputer': 'simple', 'keep_first': 1}. Best is trial 13 with value: 0.802258939709348.\n",
            "[I 2023-07-26 12:14:43,315] Trial 17 finished with value: 0.7977077045654131 and parameters: {'classifier': 'LogisticRegression', 'drop_and_winsorize': 1, 'columns_to_drop': 'useless', 'add_indicator': 1, 'imputer': 'simple', 'keep_first': 1}. Best is trial 13 with value: 0.802258939709348.\n",
            "[I 2023-07-26 12:14:45,491] Trial 18 finished with value: 0.8050497139585853 and parameters: {'classifier': 'LogisticRegression', 'drop_and_winsorize': 1, 'columns_to_drop': 'useless', 'add_indicator': 1, 'imputer': 'simple', 'keep_first': 1}. Best is trial 18 with value: 0.8050497139585853.\n",
            "[I 2023-07-26 13:01:09,940] Trial 10 finished with value: 0.6196991984983495 and parameters: {'classifier': 'SVC', 'drop_and_winsorize': 1, 'columns_to_drop': 'sparse', 'add_indicator': 1, 'imputer': 'simple', 'keep_first': 0}. Best is trial 18 with value: 0.8050497139585853.\n",
            "[I 2023-07-26 13:01:11,681] Trial 19 finished with value: 0.6797983407133769 and parameters: {'classifier': 'SVC', 'drop_and_winsorize': 1, 'columns_to_drop': 'useless', 'add_indicator': 1, 'imputer': 'knn', 'keep_first': 1}. Best is trial 18 with value: 0.8050497139585853.\n",
            "[I 2023-07-26 13:01:37,261] Trial 21 finished with value: 0.5293448242735398 and parameters: {'classifier': 'RandomForest', 'drop_and_winsorize': 1, 'columns_to_drop': 'useless', 'add_indicator': 1, 'imputer': 'simple', 'keep_first': 1}. Best is trial 18 with value: 0.8050497139585853.\n",
            "[I 2023-07-26 13:01:39,415] Trial 22 finished with value: 0.800385180058419 and parameters: {'classifier': 'LogisticRegression', 'drop_and_winsorize': 1, 'columns_to_drop': 'useless', 'add_indicator': 1, 'imputer': 'simple', 'keep_first': 1}. Best is trial 18 with value: 0.8050497139585853.\n",
            "[I 2023-07-26 13:01:41,902] Trial 23 finished with value: 0.8036291493325819 and parameters: {'classifier': 'LogisticRegression', 'drop_and_winsorize': 1, 'columns_to_drop': 'useless', 'add_indicator': 1, 'imputer': 'simple', 'keep_first': 1}. Best is trial 18 with value: 0.8050497139585853.\n",
            "[I 2023-07-26 13:01:44,309] Trial 24 finished with value: 0.7974811070529502 and parameters: {'classifier': 'LogisticRegression', 'drop_and_winsorize': 1, 'columns_to_drop': 'useless', 'add_indicator': 1, 'imputer': 'simple', 'keep_first': 1}. Best is trial 18 with value: 0.8050497139585853.\n",
            "[I 2023-07-26 13:01:47,653] Trial 25 finished with value: 0.8015791471719595 and parameters: {'classifier': 'LogisticRegression', 'drop_and_winsorize': 1, 'columns_to_drop': 'useless', 'add_indicator': 1, 'imputer': 'simple', 'keep_first': 1}. Best is trial 18 with value: 0.8050497139585853.\n",
            "[I 2023-07-26 13:01:50,199] Trial 26 finished with value: 0.7885780925739228 and parameters: {'classifier': 'LogisticRegression', 'drop_and_winsorize': 1, 'columns_to_drop': 'useless', 'add_indicator': 1, 'imputer': 'simple', 'keep_first': 1}. Best is trial 18 with value: 0.8050497139585853.\n",
            "[I 2023-07-26 13:04:10,012] Trial 20 finished with value: 0.5314093793870903 and parameters: {'classifier': 'RandomForest', 'drop_and_winsorize': 1, 'columns_to_drop': 'useless', 'add_indicator': 1, 'imputer': 'knn', 'keep_first': 1}. Best is trial 18 with value: 0.8050497139585853.\n",
            "[I 2023-07-26 13:04:12,381] Trial 28 finished with value: 0.8018454751387352 and parameters: {'classifier': 'LogisticRegression', 'drop_and_winsorize': 1, 'columns_to_drop': 'useless', 'add_indicator': 1, 'imputer': 'simple', 'keep_first': 1}. Best is trial 18 with value: 0.8050497139585853.\n",
            "[I 2023-07-26 13:04:15,105] Trial 29 finished with value: 0.7902775739173942 and parameters: {'classifier': 'LogisticRegression', 'drop_and_winsorize': 1, 'columns_to_drop': 'useless', 'add_indicator': 1, 'imputer': 'simple', 'keep_first': 1}. Best is trial 18 with value: 0.8050497139585853.\n",
            "[I 2023-07-26 13:04:15,352] Trial 27 finished with value: 0.7892201188592343 and parameters: {'classifier': 'LogisticRegression', 'drop_and_winsorize': 1, 'columns_to_drop': 'useless', 'add_indicator': 1, 'imputer': 'knn', 'keep_first': 1}. Best is trial 18 with value: 0.8050497139585853.\n",
            "[I 2023-07-26 13:04:43,656] Trial 31 finished with value: 0.6419309322210949 and parameters: {'classifier': 'XGBoost', 'drop_and_winsorize': 1, 'columns_to_drop': 'useless', 'add_indicator': 1, 'imputer': 'simple', 'keep_first': 1}. Best is trial 18 with value: 0.8050497139585853.\n",
            "[I 2023-07-26 13:04:46,720] Trial 32 finished with value: 0.7960227761748697 and parameters: {'classifier': 'LogisticRegression', 'drop_and_winsorize': 1, 'columns_to_drop': 'useless', 'add_indicator': 1, 'imputer': 'simple', 'keep_first': 1}. Best is trial 18 with value: 0.8050497139585853.\n",
            "[I 2023-07-26 13:04:49,297] Trial 33 finished with value: 0.7910057572553166 and parameters: {'classifier': 'LogisticRegression', 'drop_and_winsorize': 1, 'columns_to_drop': 'useless', 'add_indicator': 1, 'imputer': 'simple', 'keep_first': 1}. Best is trial 18 with value: 0.8050497139585853.\n",
            "[I 2023-07-26 13:04:51,492] Trial 34 finished with value: 0.805729506495974 and parameters: {'classifier': 'LogisticRegression', 'drop_and_winsorize': 1, 'columns_to_drop': 'useless', 'add_indicator': 1, 'imputer': 'simple', 'keep_first': 1}. Best is trial 34 with value: 0.805729506495974.\n",
            "[I 2023-07-26 13:04:53,167] Trial 35 finished with value: 0.6648228164588719 and parameters: {'classifier': 'LogisticRegression', 'drop_and_winsorize': 1, 'columns_to_drop': 'sparse', 'add_indicator': 1, 'imputer': 'simple', 'keep_first': 1}. Best is trial 34 with value: 0.805729506495974.\n",
            "[I 2023-07-26 13:05:24,346] Trial 36 finished with value: 0.5309184181100874 and parameters: {'classifier': 'RandomForest', 'drop_and_winsorize': 0, 'columns_to_drop': 'useless', 'add_indicator': 0, 'imputer': 'simple', 'keep_first': 1}. Best is trial 34 with value: 0.805729506495974.\n",
            "[I 2023-07-26 13:07:11,499] Trial 30 finished with value: 0.6510983104646624 and parameters: {'classifier': 'XGBoost', 'drop_and_winsorize': 1, 'columns_to_drop': 'useless', 'add_indicator': 1, 'imputer': 'knn', 'keep_first': 1}. Best is trial 34 with value: 0.805729506495974.\n",
            "[I 2023-07-26 13:07:13,503] Trial 38 finished with value: 0.6632704717192377 and parameters: {'classifier': 'LogisticRegression', 'drop_and_winsorize': 1, 'columns_to_drop': 'sparse', 'add_indicator': 0, 'imputer': 'simple', 'keep_first': 0}. Best is trial 34 with value: 0.805729506495974.\n",
            "[I 2023-07-26 13:07:30,911] Trial 37 finished with value: 0.6614993862760833 and parameters: {'classifier': 'LogisticRegression', 'drop_and_winsorize': 1, 'columns_to_drop': 'sparse', 'add_indicator': 1, 'imputer': 'knn', 'keep_first': 1}. Best is trial 34 with value: 0.805729506495974.\n",
            "[I 2023-07-26 13:45:46,787] Trial 39 finished with value: 0.6623312259228983 and parameters: {'classifier': 'SVC', 'drop_and_winsorize': 0, 'columns_to_drop': 'useless', 'add_indicator': 1, 'imputer': 'simple', 'keep_first': 1}. Best is trial 34 with value: 0.805729506495974.\n",
            "[I 2023-07-26 13:46:22,789] Trial 41 finished with value: 0.6476588137861283 and parameters: {'classifier': 'XGBoost', 'drop_and_winsorize': 0, 'columns_to_drop': 'useless', 'add_indicator': 0, 'imputer': 'simple', 'keep_first': 0}. Best is trial 34 with value: 0.805729506495974.\n",
            "[I 2023-07-26 13:46:24,891] Trial 42 finished with value: 0.8022715284600405 and parameters: {'classifier': 'LogisticRegression', 'drop_and_winsorize': 1, 'columns_to_drop': 'useless', 'add_indicator': 1, 'imputer': 'simple', 'keep_first': 1}. Best is trial 34 with value: 0.805729506495974.\n",
            "[I 2023-07-26 13:46:27,005] Trial 43 finished with value: 0.8036920930860438 and parameters: {'classifier': 'LogisticRegression', 'drop_and_winsorize': 1, 'columns_to_drop': 'useless', 'add_indicator': 1, 'imputer': 'simple', 'keep_first': 1}. Best is trial 34 with value: 0.805729506495974.\n",
            "[I 2023-07-26 13:46:29,148] Trial 44 finished with value: 0.800385180058419 and parameters: {'classifier': 'LogisticRegression', 'drop_and_winsorize': 1, 'columns_to_drop': 'useless', 'add_indicator': 1, 'imputer': 'simple', 'keep_first': 1}. Best is trial 34 with value: 0.805729506495974.\n",
            "[I 2023-07-26 13:46:32,532] Trial 45 finished with value: 0.789509660125159 and parameters: {'classifier': 'LogisticRegression', 'drop_and_winsorize': 1, 'columns_to_drop': 'useless', 'add_indicator': 1, 'imputer': 'simple', 'keep_first': 1}. Best is trial 34 with value: 0.805729506495974.\n",
            "[I 2023-07-26 13:46:34,272] Trial 46 finished with value: 0.6604167537165384 and parameters: {'classifier': 'LogisticRegression', 'drop_and_winsorize': 1, 'columns_to_drop': 'sparse', 'add_indicator': 1, 'imputer': 'simple', 'keep_first': 1}. Best is trial 34 with value: 0.805729506495974.\n",
            "[I 2023-07-26 13:49:47,851] Trial 40 finished with value: 0.6664989059393547 and parameters: {'classifier': 'SVC', 'drop_and_winsorize': 0, 'columns_to_drop': 'useless', 'add_indicator': 1, 'imputer': 'simple', 'keep_first': 0}. Best is trial 34 with value: 0.805729506495974.\n",
            "[I 2023-07-26 13:49:49,973] Trial 48 finished with value: 0.7999843042384984 and parameters: {'classifier': 'LogisticRegression', 'drop_and_winsorize': 1, 'columns_to_drop': 'useless', 'add_indicator': 1, 'imputer': 'simple', 'keep_first': 1}. Best is trial 34 with value: 0.805729506495974.\n",
            "[I 2023-07-26 13:50:11,771] Trial 49 finished with value: 0.525710603727913 and parameters: {'classifier': 'RandomForest', 'drop_and_winsorize': 1, 'columns_to_drop': 'useless', 'add_indicator': 1, 'imputer': 'simple', 'keep_first': 1}. Best is trial 34 with value: 0.805729506495974.\n",
            "[I 2023-07-26 13:50:13,853] Trial 50 finished with value: 0.8065583998394354 and parameters: {'classifier': 'LogisticRegression', 'drop_and_winsorize': 1, 'columns_to_drop': 'useless', 'add_indicator': 1, 'imputer': 'simple', 'keep_first': 1}. Best is trial 50 with value: 0.8065583998394354.\n",
            "[I 2023-07-26 13:50:15,553] Trial 51 finished with value: 0.6636123321901676 and parameters: {'classifier': 'LogisticRegression', 'drop_and_winsorize': 1, 'columns_to_drop': 'sparse', 'add_indicator': 1, 'imputer': 'simple', 'keep_first': 1}. Best is trial 50 with value: 0.8065583998394354.\n",
            "[I 2023-07-26 13:50:17,693] Trial 52 finished with value: 0.7995562867149575 and parameters: {'classifier': 'LogisticRegression', 'drop_and_winsorize': 1, 'columns_to_drop': 'useless', 'add_indicator': 1, 'imputer': 'simple', 'keep_first': 1}. Best is trial 50 with value: 0.8065583998394354.\n",
            "[I 2023-07-26 13:50:20,896] Trial 53 finished with value: 0.7999823400362627 and parameters: {'classifier': 'LogisticRegression', 'drop_and_winsorize': 1, 'columns_to_drop': 'useless', 'add_indicator': 1, 'imputer': 'simple', 'keep_first': 1}. Best is trial 50 with value: 0.8065583998394354.\n",
            "[I 2023-07-26 13:50:23,187] Trial 54 finished with value: 0.8049867702051234 and parameters: {'classifier': 'LogisticRegression', 'drop_and_winsorize': 1, 'columns_to_drop': 'useless', 'add_indicator': 1, 'imputer': 'simple', 'keep_first': 1}. Best is trial 50 with value: 0.8065583998394354.\n",
            "[I 2023-07-26 13:50:25,298] Trial 55 finished with value: 0.8029387322467367 and parameters: {'classifier': 'LogisticRegression', 'drop_and_winsorize': 1, 'columns_to_drop': 'useless', 'add_indicator': 1, 'imputer': 'simple', 'keep_first': 1}. Best is trial 50 with value: 0.8065583998394354.\n",
            "[I 2023-07-26 13:52:42,573] Trial 56 finished with value: 0.7847947712222231 and parameters: {'classifier': 'LogisticRegression', 'drop_and_winsorize': 1, 'columns_to_drop': 'useless', 'add_indicator': 1, 'imputer': 'knn', 'keep_first': 1}. Best is trial 50 with value: 0.8065583998394354.\n",
            "[I 2023-07-26 14:30:13,993] Trial 47 finished with value: 0.6813593457992321 and parameters: {'classifier': 'SVC', 'drop_and_winsorize': 1, 'columns_to_drop': 'useless', 'add_indicator': 1, 'imputer': 'simple', 'keep_first': 1}. Best is trial 50 with value: 0.8065583998394354.\n",
            "[I 2023-07-26 14:30:17,329] Trial 58 finished with value: 0.7920506235627843 and parameters: {'classifier': 'LogisticRegression', 'drop_and_winsorize': 1, 'columns_to_drop': 'useless', 'add_indicator': 1, 'imputer': 'simple', 'keep_first': 1}. Best is trial 50 with value: 0.8065583998394354.\n",
            "[I 2023-07-26 14:30:19,538] Trial 59 finished with value: 0.7806066456461315 and parameters: {'classifier': 'LogisticRegression', 'drop_and_winsorize': 1, 'columns_to_drop': 'useless', 'add_indicator': 1, 'imputer': 'simple', 'keep_first': 1}. Best is trial 50 with value: 0.8065583998394354.\n",
            "[I 2023-07-26 14:30:44,567] Trial 60 finished with value: 0.6581275652927607 and parameters: {'classifier': 'XGBoost', 'drop_and_winsorize': 1, 'columns_to_drop': 'useless', 'add_indicator': 1, 'imputer': 'simple', 'keep_first': 1}. Best is trial 50 with value: 0.8065583998394354.\n",
            "[I 2023-07-26 14:31:03,572] Trial 61 finished with value: 0.5292315255173083 and parameters: {'classifier': 'RandomForest', 'drop_and_winsorize': 1, 'columns_to_drop': 'useless', 'add_indicator': 1, 'imputer': 'simple', 'keep_first': 1}. Best is trial 50 with value: 0.8065583998394354.\n",
            "[I 2023-07-26 14:31:05,880] Trial 62 finished with value: 0.7931564694214781 and parameters: {'classifier': 'LogisticRegression', 'drop_and_winsorize': 1, 'columns_to_drop': 'useless', 'add_indicator': 1, 'imputer': 'simple', 'keep_first': 1}. Best is trial 50 with value: 0.8065583998394354.\n",
            "[I 2023-07-26 14:31:08,955] Trial 63 finished with value: 0.8024100047176567 and parameters: {'classifier': 'LogisticRegression', 'drop_and_winsorize': 1, 'columns_to_drop': 'useless', 'add_indicator': 1, 'imputer': 'simple', 'keep_first': 1}. Best is trial 50 with value: 0.8065583998394354.\n",
            "[I 2023-07-26 14:31:11,161] Trial 64 finished with value: 0.7902146301639323 and parameters: {'classifier': 'LogisticRegression', 'drop_and_winsorize': 1, 'columns_to_drop': 'useless', 'add_indicator': 1, 'imputer': 'simple', 'keep_first': 1}. Best is trial 50 with value: 0.8065583998394354.\n",
            "[I 2023-07-26 14:31:13,307] Trial 65 finished with value: 0.7939727740142473 and parameters: {'classifier': 'LogisticRegression', 'drop_and_winsorize': 1, 'columns_to_drop': 'useless', 'add_indicator': 1, 'imputer': 'simple', 'keep_first': 1}. Best is trial 50 with value: 0.8065583998394354.\n",
            "[I 2023-07-26 14:33:15,116] Trial 66 finished with value: 0.7833470648925992 and parameters: {'classifier': 'LogisticRegression', 'drop_and_winsorize': 1, 'columns_to_drop': 'useless', 'add_indicator': 1, 'imputer': 'knn', 'keep_first': 1}. Best is trial 50 with value: 0.8065583998394354.\n",
            "[I 2023-07-26 14:33:17,212] Trial 67 finished with value: 0.7910057572553166 and parameters: {'classifier': 'LogisticRegression', 'drop_and_winsorize': 1, 'columns_to_drop': 'useless', 'add_indicator': 1, 'imputer': 'simple', 'keep_first': 1}. Best is trial 50 with value: 0.8065583998394354.\n",
            "[I 2023-07-26 14:33:19,308] Trial 68 finished with value: 0.790590328482468 and parameters: {'classifier': 'LogisticRegression', 'drop_and_winsorize': 1, 'columns_to_drop': 'useless', 'add_indicator': 1, 'imputer': 'simple', 'keep_first': 1}. Best is trial 50 with value: 0.8065583998394354.\n",
            "[I 2023-07-26 14:33:21,484] Trial 69 finished with value: 0.7887417463329237 and parameters: {'classifier': 'LogisticRegression', 'drop_and_winsorize': 1, 'columns_to_drop': 'useless', 'add_indicator': 1, 'imputer': 'simple', 'keep_first': 1}. Best is trial 50 with value: 0.8065583998394354.\n",
            "[I 2023-07-26 14:33:23,642] Trial 70 finished with value: 0.7888821867927756 and parameters: {'classifier': 'LogisticRegression', 'drop_and_winsorize': 1, 'columns_to_drop': 'useless', 'add_indicator': 1, 'imputer': 'simple', 'keep_first': 1}. Best is trial 50 with value: 0.8065583998394354.\n",
            "[I 2023-07-26 14:33:41,718] Trial 71 finished with value: 0.6517002491679817 and parameters: {'classifier': 'XGBoost', 'drop_and_winsorize': 1, 'columns_to_drop': 'sparse', 'add_indicator': 0, 'imputer': 'simple', 'keep_first': 1}. Best is trial 50 with value: 0.8065583998394354.\n",
            "[I 2023-07-26 14:33:43,887] Trial 72 finished with value: 0.7914337747788576 and parameters: {'classifier': 'LogisticRegression', 'drop_and_winsorize': 1, 'columns_to_drop': 'useless', 'add_indicator': 1, 'imputer': 'simple', 'keep_first': 1}. Best is trial 50 with value: 0.8065583998394354.\n",
            "[I 2023-07-26 14:33:46,014] Trial 73 finished with value: 0.7896984913855447 and parameters: {'classifier': 'LogisticRegression', 'drop_and_winsorize': 1, 'columns_to_drop': 'useless', 'add_indicator': 1, 'imputer': 'simple', 'keep_first': 1}. Best is trial 50 with value: 0.8065583998394354.\n",
            "[I 2023-07-26 14:33:48,176] Trial 74 finished with value: 0.7952674511333269 and parameters: {'classifier': 'LogisticRegression', 'drop_and_winsorize': 1, 'columns_to_drop': 'useless', 'add_indicator': 1, 'imputer': 'simple', 'keep_first': 1}. Best is trial 50 with value: 0.8065583998394354.\n",
            "[I 2023-07-26 14:33:50,966] Trial 75 finished with value: 0.7921745468674724 and parameters: {'classifier': 'LogisticRegression', 'drop_and_winsorize': 1, 'columns_to_drop': 'useless', 'add_indicator': 1, 'imputer': 'simple', 'keep_first': 1}. Best is trial 50 with value: 0.8065583998394354.\n",
            "[I 2023-07-26 14:33:53,705] Trial 76 finished with value: 0.7952548623826344 and parameters: {'classifier': 'LogisticRegression', 'drop_and_winsorize': 1, 'columns_to_drop': 'useless', 'add_indicator': 1, 'imputer': 'simple', 'keep_first': 1}. Best is trial 50 with value: 0.8065583998394354.\n",
            "[I 2023-07-26 14:38:02,409] Trial 57 finished with value: 0.680201180735533 and parameters: {'classifier': 'SVC', 'drop_and_winsorize': 1, 'columns_to_drop': 'useless', 'add_indicator': 1, 'imputer': 'simple', 'keep_first': 1}. Best is trial 50 with value: 0.8065583998394354.\n",
            "[I 2023-07-26 14:40:06,826] Trial 78 finished with value: 0.7850068157817578 and parameters: {'classifier': 'LogisticRegression', 'drop_and_winsorize': 1, 'columns_to_drop': 'useless', 'add_indicator': 1, 'imputer': 'knn', 'keep_first': 1}. Best is trial 50 with value: 0.8065583998394354.\n",
            "[I 2023-07-26 14:40:09,064] Trial 79 finished with value: 0.7863034571030731 and parameters: {'classifier': 'LogisticRegression', 'drop_and_winsorize': 1, 'columns_to_drop': 'useless', 'add_indicator': 1, 'imputer': 'simple', 'keep_first': 0}. Best is trial 50 with value: 0.8065583998394354.\n",
            "[I 2023-07-26 14:40:29,949] Trial 80 finished with value: 0.527546597126765 and parameters: {'classifier': 'RandomForest', 'drop_and_winsorize': 1, 'columns_to_drop': 'useless', 'add_indicator': 1, 'imputer': 'simple', 'keep_first': 1}. Best is trial 50 with value: 0.8065583998394354.\n",
            "[I 2023-07-26 14:40:32,020] Trial 81 finished with value: 0.7998961829836517 and parameters: {'classifier': 'LogisticRegression', 'drop_and_winsorize': 1, 'columns_to_drop': 'useless', 'add_indicator': 1, 'imputer': 'simple', 'keep_first': 1}. Best is trial 50 with value: 0.8065583998394354.\n",
            "[I 2023-07-26 14:40:34,152] Trial 82 finished with value: 0.792061248111241 and parameters: {'classifier': 'LogisticRegression', 'drop_and_winsorize': 1, 'columns_to_drop': 'useless', 'add_indicator': 1, 'imputer': 'simple', 'keep_first': 1}. Best is trial 50 with value: 0.8065583998394354.\n",
            "[I 2023-07-26 14:40:37,465] Trial 83 finished with value: 0.7907665709921614 and parameters: {'classifier': 'LogisticRegression', 'drop_and_winsorize': 1, 'columns_to_drop': 'useless', 'add_indicator': 1, 'imputer': 'simple', 'keep_first': 1}. Best is trial 50 with value: 0.8065583998394354.\n",
            "[I 2023-07-26 14:40:39,616] Trial 84 finished with value: 0.787938030490847 and parameters: {'classifier': 'LogisticRegression', 'drop_and_winsorize': 1, 'columns_to_drop': 'useless', 'add_indicator': 1, 'imputer': 'simple', 'keep_first': 1}. Best is trial 50 with value: 0.8065583998394354.\n",
            "[I 2023-07-26 14:40:41,724] Trial 85 finished with value: 0.7992541566983403 and parameters: {'classifier': 'LogisticRegression', 'drop_and_winsorize': 1, 'columns_to_drop': 'useless', 'add_indicator': 1, 'imputer': 'simple', 'keep_first': 1}. Best is trial 50 with value: 0.8065583998394354.\n",
            "[I 2023-07-26 14:40:43,376] Trial 86 finished with value: 0.6668979961208792 and parameters: {'classifier': 'LogisticRegression', 'drop_and_winsorize': 1, 'columns_to_drop': 'sparse', 'add_indicator': 1, 'imputer': 'simple', 'keep_first': 1}. Best is trial 50 with value: 0.8065583998394354.\n",
            "[I 2023-07-26 14:40:45,458] Trial 87 finished with value: 0.8014552238672714 and parameters: {'classifier': 'LogisticRegression', 'drop_and_winsorize': 1, 'columns_to_drop': 'useless', 'add_indicator': 1, 'imputer': 'simple', 'keep_first': 1}. Best is trial 50 with value: 0.8065583998394354.\n",
            "[I 2023-07-26 14:40:47,681] Trial 88 finished with value: 0.8000956387924942 and parameters: {'classifier': 'LogisticRegression', 'drop_and_winsorize': 1, 'columns_to_drop': 'useless', 'add_indicator': 1, 'imputer': 'simple', 'keep_first': 1}. Best is trial 50 with value: 0.8065583998394354.\n",
            "[I 2023-07-26 15:12:09,050] Trial 77 finished with value: 0.6815607658103102 and parameters: {'classifier': 'SVC', 'drop_and_winsorize': 1, 'columns_to_drop': 'useless', 'add_indicator': 1, 'imputer': 'knn', 'keep_first': 1}. Best is trial 50 with value: 0.8065583998394354.\n",
            "[I 2023-07-26 15:12:11,391] Trial 90 finished with value: 0.8039438680998914 and parameters: {'classifier': 'LogisticRegression', 'drop_and_winsorize': 1, 'columns_to_drop': 'useless', 'add_indicator': 1, 'imputer': 'simple', 'keep_first': 1}. Best is trial 50 with value: 0.8065583998394354.\n",
            "[I 2023-07-26 15:12:36,119] Trial 91 finished with value: 0.6423085947418663 and parameters: {'classifier': 'XGBoost', 'drop_and_winsorize': 1, 'columns_to_drop': 'useless', 'add_indicator': 1, 'imputer': 'simple', 'keep_first': 1}. Best is trial 50 with value: 0.8065583998394354.\n",
            "[I 2023-07-26 15:12:38,312] Trial 92 finished with value: 0.7881752525517665 and parameters: {'classifier': 'LogisticRegression', 'drop_and_winsorize': 1, 'columns_to_drop': 'useless', 'add_indicator': 1, 'imputer': 'simple', 'keep_first': 1}. Best is trial 50 with value: 0.8065583998394354.\n",
            "[I 2023-07-26 15:12:40,499] Trial 93 finished with value: 0.8014678126179637 and parameters: {'classifier': 'LogisticRegression', 'drop_and_winsorize': 1, 'columns_to_drop': 'useless', 'add_indicator': 1, 'imputer': 'simple', 'keep_first': 1}. Best is trial 50 with value: 0.8065583998394354.\n",
            "[I 2023-07-26 15:12:43,385] Trial 94 finished with value: 0.7973300420446416 and parameters: {'classifier': 'LogisticRegression', 'drop_and_winsorize': 1, 'columns_to_drop': 'useless', 'add_indicator': 1, 'imputer': 'simple', 'keep_first': 1}. Best is trial 50 with value: 0.8065583998394354.\n",
            "[I 2023-07-26 15:12:46,128] Trial 95 finished with value: 0.7883156930116184 and parameters: {'classifier': 'LogisticRegression', 'drop_and_winsorize': 1, 'columns_to_drop': 'useless', 'add_indicator': 1, 'imputer': 'simple', 'keep_first': 1}. Best is trial 50 with value: 0.8065583998394354.\n",
            "[I 2023-07-26 15:12:48,333] Trial 96 finished with value: 0.7821405090283663 and parameters: {'classifier': 'LogisticRegression', 'drop_and_winsorize': 1, 'columns_to_drop': 'useless', 'add_indicator': 1, 'imputer': 'simple', 'keep_first': 1}. Best is trial 50 with value: 0.8065583998394354.\n",
            "[I 2023-07-26 15:12:50,520] Trial 97 finished with value: 0.786102037091995 and parameters: {'classifier': 'LogisticRegression', 'drop_and_winsorize': 1, 'columns_to_drop': 'useless', 'add_indicator': 1, 'imputer': 'simple', 'keep_first': 1}. Best is trial 50 with value: 0.8065583998394354.\n",
            "[I 2023-07-26 15:12:52,813] Trial 98 finished with value: 0.784266043693143 and parameters: {'classifier': 'LogisticRegression', 'drop_and_winsorize': 1, 'columns_to_drop': 'useless', 'add_indicator': 1, 'imputer': 'simple', 'keep_first': 1}. Best is trial 50 with value: 0.8065583998394354.\n",
            "[I 2023-07-26 15:13:16,815] Trial 99 finished with value: 0.5275359725783083 and parameters: {'classifier': 'RandomForest', 'drop_and_winsorize': 0, 'columns_to_drop': 'useless', 'add_indicator': 1, 'imputer': 'simple', 'keep_first': 1}. Best is trial 50 with value: 0.8065583998394354.\n",
            "[I 2023-07-26 15:15:30,712] Trial 89 finished with value: 0.6793199681870663 and parameters: {'classifier': 'SVC', 'drop_and_winsorize': 1, 'columns_to_drop': 'useless', 'add_indicator': 1, 'imputer': 'knn', 'keep_first': 1}. Best is trial 50 with value: 0.8065583998394354.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f1_score: 0.8065583998394354\n",
            "Best hyperparameters: {'classifier': 'LogisticRegression', 'drop_and_winsorize': 1, 'columns_to_drop': 'useless', 'add_indicator': 1, 'imputer': 'simple', 'keep_first': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameter tuning of the best model using optuna"
      ],
      "metadata": {
        "id": "Z078dr2a9Nn7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# getting the full data set\n",
        "\n",
        "# spliting X_train and y_train\n",
        "y_train = LabelEncoder().fit_transform(raw_data['went_on_backorder'])\n",
        "X_train = raw_data.drop('went_on_backorder',axis=1)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)"
      ],
      "metadata": {
        "id": "zbLWo0vs9o3i",
        "outputId": "88a2cdb1-22d9-47f6-8278-084164e85d24",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1687860, 22)\n",
            "(1687860,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining Objective function which will be optimized\n",
        "\n",
        "def objective(trial):\n",
        ""
      ],
      "metadata": {
        "id": "fdZhupbc903y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Defining Objective function which will be optimized\n",
        "\n",
        "# def objective(trial):\n",
        "\n",
        "#     # Sampling the classifier type along with its parameter\n",
        "#     classifier = trial.suggest_categorical('classifier', ['RandomForest', 'SVC', 'LogisticRegression', 'XGBoost'])\n",
        "\n",
        "#     if classifier == 'RandomForest':\n",
        "#         # Sampling hyperparameters for RandomForestClassifier\n",
        "#         n_estimators = trial.suggest_int('n_estimators', 50, 300, step=50)\n",
        "#         max_depth = trial.suggest_int('max_depth', 5, 20)\n",
        "#         min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n",
        "#         min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)\n",
        "\n",
        "#         clf = RandomForestClassifier(\n",
        "#             n_estimators=n_estimators,\n",
        "#             max_depth=max_depth,\n",
        "#             min_samples_split=min_samples_split,\n",
        "#             min_samples_leaf=min_samples_leaf\n",
        "#         )\n",
        "\n",
        "#     elif classifier == 'SVC':\n",
        "#         # Sampling hyperparameters for SVC\n",
        "#         C = trial.suggest_loguniform('svc_C', 1e-3, 1e3)\n",
        "#         kernel = trial.suggest_categorical('svc_kernel', ['linear', 'poly', 'rbf', 'sigmoid'])\n",
        "#         gamma = trial.suggest_categorical('svc_gamma', ['scale', 'auto'])\n",
        "\n",
        "#         clf = SVC(C=C, kernel=kernel, gamma=gamma)\n",
        "\n",
        "#     elif classifier == 'LogisticRegression':\n",
        "#         # Sampling hyperparameters for LogisticRegression\n",
        "#         C = trial.suggest_loguniform('lr_C', 1e-3, 1e3)\n",
        "#         penalty = trial.suggest_categorical('lr_penalty', ['l1', 'l2'])\n",
        "\n",
        "#         clf = LogisticRegression(C=C, penalty=penalty, solver='liblinear')\n",
        "\n",
        "#     elif classifier == 'XGBoost':\n",
        "#         # Sampling hyperparameters for XGBoostClassifier\n",
        "#         n_estimators = trial.suggest_int('xgb_n_estimators', 50, 300, step=50)\n",
        "#         max_depth = trial.suggest_int('xgb_max_depth', 3, 10)\n",
        "#         learning_rate = trial.suggest_loguniform('xgb_learning_rate', 0.01, 0.1)\n",
        "#         subsample = trial.suggest_uniform('xgb_subsample', 0.6, 0.9)\n",
        "\n",
        "#         clf = XGBClassifier(\n",
        "#             n_estimators=n_estimators,\n",
        "#             max_depth=max_depth,\n",
        "#             learning_rate=learning_rate,\n",
        "#             subsample=subsample\n",
        "#         )\n",
        "\n",
        "#     # experimenting with dropping unnecessary columns and outlier handling\n",
        "#     drop_and_winsorize = trial.suggest_int('drop_and_winsorize',0,1)\n",
        "\n",
        "#     if drop_and_winsorize:\n",
        "#       # experimenting with columns to drop\n",
        "#       columns_to_drop = trial.suggest_categorical('columns_to_drop', ['useless', 'sparse'])\n",
        "#       drop_cols = useless_cols if columns_to_drop=='useless' else sparse_cols\n",
        "#       num_cols_used = [col for col in numeric_cols if col not in drop_cols]\n",
        "#       cat_cols_used = [col for col in cat_cols if col not in drop_cols]\n",
        "#     else:\n",
        "#       drop_cols, num_cols_used, cat_cols_used = [], [], []\n",
        "\n",
        "#     # experimenting with imputers\n",
        "#     add_indicator = trial.suggest_int('add_indicator',0,1)\n",
        "#     imputer = trial.suggest_categorical('imputer',['simple','knn'])\n",
        "\n",
        "#     if imputer == 'knn':\n",
        "#       imp = KNNImputer(weights='distance', add_indicator=add_indicator)\n",
        "#     else:\n",
        "#       imp = SimpleImputer(strategy='median', add_indicator=add_indicator)\n",
        "\n",
        "#     # experimenting with one hot encoding\n",
        "#     keep_first = trial.suggest_int('keep_first',0,1)\n",
        "#     cat_encoder = OneHotEncoder(drop='first') if keep_first else OneHotEncoder()\n",
        "\n",
        "#     # Constructing the numerical pipeline\n",
        "#     num_pipeline = Pipeline([\n",
        "#         ('scaler', StandardScaler()),\n",
        "#         ('imputer', imp),\n",
        "#         ('outlier_clipping', Winsorizer(change=drop_and_winsorize)),\n",
        "#     ])\n",
        "#     # constructing categorical pipeline\n",
        "#     cat_pipeline = Pipeline([\n",
        "#         ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "#         ('onehotencoder', cat_encoder),\n",
        "#     ])\n",
        "\n",
        "#     # constructing training pipeline\n",
        "#     training_pipeline = Pipeline([\n",
        "#         ('Drop_Columns', FunctionTransformer(drop_col, kw_args={'columns': drop_cols, 'drop': drop_and_winsorize})),\n",
        "#         ('Balancing', RandomOverSampler()),\n",
        "#         ('Feature_transform', ColumnTransformer([\n",
        "#             ('num_pipeline', num_pipeline, num_cols_used),\n",
        "#             ('cat_pipeline', cat_pipeline, cat_cols_used),\n",
        "#             ])),\n",
        "\n",
        "#     ('Model training', clf)\n",
        "#     ])\n",
        "\n",
        "#     scorer = make_scorer(f1_score)\n",
        "\n",
        "#     scores = cross_val_score(training_pipeline, X_train, y_train, n_jobs=-1, cv=5, scoring=scorer)\n",
        "#     # report_cross_validation_scores(trial, scores)\n",
        "\n",
        "#     # Returning the cross-validated mean score\n",
        "#     return scores.mean()\n"
      ],
      "metadata": {
        "id": "9V7ohvEVboTV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# study = optuna.create_study(direction=\"maximize\")\n",
        "# # terminator = TerminatorCallback()\n",
        "# study.optimize(objective, n_trials=100, n_jobs=2, )#, #callbacks=[terminator])\n",
        "# trial = study.best_trial\n",
        "\n",
        "# print('f1_score: {}'.format(trial.value))\n",
        "# print(\"Best hyperparameters: {}\".format(trial.params))\n"
      ],
      "metadata": {
        "id": "-foBm_DLgsz_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}